if __name__ == "__main__":
    import sys
    import os
    import pathlib

    ROOT_DIR = str(pathlib.Path(__file__).parent.absolute())
    sys.path.append(ROOT_DIR)

import hydra
import torch
import zarr
import numpy as np
import time
from tqdm import tqdm
from omegaconf import OmegaConf
from diffusion_policy_3d.workspace.balancer_workspace import BalancerWorkspace
from diffusion_policy_3d.common.pytorch_util import dict_apply

# ==========================================
# GPU K-Means å®ç°
# ==========================================
def kmeans_pytorch(X, k=100, n_iter=30, batch_size=50000, tol=1e-4, verbose=True):
    """
    X: (N, d) Tensor on GPU
    """
    device = X.device
    N, d = X.shape
    
    # éšæœºåˆå§‹åŒ–ä¸­å¿ƒ
    idx = torch.randperm(N, device=device)[:k]
    centers = X[idx].clone()

    for it in range(n_iter):
        t0 = time.time()
        new_centers_sum = torch.zeros((k, d), device=device)
        new_centers_count = torch.zeros(k, device=device)

        # åˆ†æ‰¹è®¡ç®—è·ç¦»ï¼Œé˜²æ­¢æ˜¾å­˜çˆ†ç‚¸
        for i in range(0, N, batch_size):
            xb = X[i:i + batch_size]
            dist = torch.cdist(xb, centers)
            labels = torch.argmin(dist, dim=1)
            
            for c in range(k):
                mask = (labels == c)
                if mask.any():
                    new_centers_sum[c] += xb[mask].sum(dim=0)
                    new_centers_count[c] += mask.sum()

        # æ›´æ–°ä¸­å¿ƒ
        updated = new_centers_sum / new_centers_count.unsqueeze(1).clamp(min=1)
        shift = torch.norm(centers - updated, dim=1).mean()
        centers = updated

        if verbose:
            print(f"[Iter {it+1}] shift={shift:.6f}, time={time.time()-t0:.3f}s")
        if shift < tol:
            break

    # æœ€åå†ç®—ä¸€æ¬¡æ‰€æœ‰æ•°æ®çš„ label
    final_labels = torch.empty(N, dtype=torch.long, device=device)
    for i in range(0, N, batch_size):
        xb = X[i:i + batch_size]
        dist = torch.cdist(xb, centers)
        final_labels[i:i + batch_size] = torch.argmin(dist, dim=1)

    cluster_density = torch.bincount(final_labels, minlength=k).float()
    return centers, final_labels, cluster_density

# ==========================================
# æ ¸å¿ƒé€»è¾‘
# ==========================================
@hydra.main(
    config_path="/home/shui/idp3_test/Improved-3D-Diffusion-Policy/Improved-3D-Diffusion-Policy/diffusion_policy_3d/config", 
    config_name="controlnet.yaml", 
    version_base=None
)
def main(cfg):
    device = torch.device(cfg.training.device)
    
    # 1. å®ä¾‹åŒ– BalancerWorkspace
    print(f"ğŸ”„ Instantiating BalancerWorkspace...")
    workspace = BalancerWorkspace(cfg)
    
    # 2. åŠ è½½ Checkpoint
    # è¯·ç¡®è®¤è¿™ä¸ªè·¯å¾„æ˜¯å¦æ­£ç¡®
    ckpt_path = pathlib.Path("/home/shui/idp3_test/Improved-3D-Diffusion-Policy/Improved-3D-Diffusion-Policy/data/outputs/-controlnet-DMP_dualarm_augment_stage1_12011325_seed0/checkpoints/latest.ckpt")    
    print(f"ğŸ“¥ Loading checkpoint from: {ckpt_path}")
    if not ckpt_path.exists():
        raise FileNotFoundError(f"Checkpoint not found: {ckpt_path}")
    
    workspace.load_checkpoint(path=ckpt_path)
    
    # 3. æå– Policy å’Œ Normalizer
    # æ ¹æ®é…ç½®å†³å®šä½¿ç”¨ ema_model è¿˜æ˜¯ model
    if cfg.stage1.training.use_ema and workspace.ema_model is not None:
        policy = workspace.ema_model
        print("âœ… Using EMA Model")
    else:
        policy = workspace.model
        print("âœ… Using Standard Model")
        
    policy.eval()
    policy.to(device)
    
    # è·å– Encoder
    encoder = policy.obs_encoder_stage1
    # è·å– Normalizer (è‡³å…³é‡è¦)
    normalizer = policy.normalizer
    
    print("ğŸ” Encoder found:", type(encoder))

# ... å‰é¢çš„ä»£ç ä¸å˜ ...

    # 4. æ‰“å¼€ Zarr æ•°æ®
    zarr_path = "/home/shui/DMP_gen/final_merged_dataset/merged_dataset_total.zarr"
    print(f"ğŸ“‚ Opening Zarr: {zarr_path}")
    root = zarr.open(zarr_path, mode='r')
    
    # [ä¿®æ”¹ç‚¹ 1] é¢„å…ˆè·å–æ‰€æœ‰éœ€è¦çš„ Array
    pc_array = root['data']['point_cloud']
    
    # å°è¯•è·å– state å’Œ action
    state_array = root['data']['state'] if 'state' in root['data'] else None
    action_array = root['data']['action'] if 'action' in root['data'] else None
    
    total_len = pc_array.shape[0]
    print(f"ğŸ“Š Total frames: {total_len}")
    if state_array is not None: print(f"   State shape: {state_array.shape}")
    if action_array is not None: print(f"   Action shape: {action_array.shape}")

    # 5. æ¨ç† Loop
    batch_size = 64
    embeddings_list = []
    
    print("ğŸš€ Starting Encoding...")
    with torch.no_grad():
        for i in tqdm(range(0, total_len, batch_size)):
            # --- A. è¯»å–æ•°æ® ---
            # 1. Point Cloud
            batch_pc = torch.from_numpy(pc_array[i : i + batch_size]).float().to(device)
            
            # 2. State (å¦‚æœæœ‰) -> æ‹†åˆ†ä¸º agent_pos / agent_rot
            # [å…³é”®] è¿™é‡Œéœ€è¦ä½ ç¡®è®¤ dataset çš„ state æ˜¯æ€ä¹ˆå®šä¹‰çš„
            # å‡è®¾: state (N, 14) -> pos (N, 10) + rot (N, 4) æˆ–è€…å…¶ä»–åˆ‡åˆ†æ–¹å¼
            # ä¸‹é¢æ˜¯ä¸€ä¸ªç¤ºä¾‹ï¼Œè¯·æ ¹æ®ä½ çš„ shape_meta ä¿®æ”¹åˆ‡ç‰‡ç´¢å¼•
            if state_array is not None:
                batch_state = torch.from_numpy(state_array[i : i + batch_size]).float().to(device)
                
                # ç¤ºä¾‹åˆ‡åˆ†ï¼šå‡è®¾å‰3ç»´æ˜¯ posï¼Œå6ç»´æ˜¯ rot (æ ¹æ®ä½ çš„ shape_meta è°ƒæ•´)
                # å¦‚æœä½ çš„ normalizer é‡Œé¢æœ‰ agent_pos å’Œ agent_rot çš„ç»Ÿè®¡ä¿¡æ¯
                # ä½ å¿…é¡»ç¡®ä¿è¿™é‡Œçš„æ•°æ®ç»´åº¦å’Œ key èƒ½å¯¹ä¸Š
                agent_pos = batch_state[:, :]  # [è¯·ä¿®æ”¹è¿™é‡Œ]
                # agent_rot = batch_state[:, 3:9] # [è¯·ä¿®æ”¹è¿™é‡Œ]
                
                # å¦‚æœ state ç»´åº¦ä¸å¤Ÿï¼Œæˆ–è€…å¯¹åº”ä¸ä¸Šï¼Œä½ å¯ä»¥ç”¨å…¨0è¡¥å…¨å‰©ä½™ç»´åº¦
                # agent_pos = torch.cat([agent_pos, torch.zeros(...)], dim=-1)
            else:
                # å¦‚æœ zarr é‡Œæ²¡ stateï¼Œåªèƒ½ç”¨ dummy
                agent_pos = None 
                agent_rot = None


            # --- B. æ„é€  Obs Dict ---
            obs_dict = {
                'point_cloud': batch_pc,
            }
            
            # å°†è¯»å–åˆ°çš„ state å¡è¿›å»
            if agent_pos is not None: obs_dict['agent_pos'] = agent_pos
            # if agent_rot is not None: obs_dict['agent_rot'] = agent_rot

            # --- C. å…œåº•é€»è¾‘ (Dummy) ---
            # å¦‚æœ Normalizer æœŸå¾…æŸäº› key (å¦‚ agent_pos)ï¼Œä½† Zarr é‡Œæ²¡æœ‰æˆ–è€…æ²¡è¯»åˆ°
            # å¿…é¡»å¡«è¡¥ Dummy æ•°æ®ï¼Œå¦åˆ™ normalizer ä¼šæŠ¥é”™
            for key in normalizer.params_dict.keys():
                if key not in obs_dict and key != 'action':
                    # è·å–è¯¥ key åœ¨ normalizer ä¸­è®°å½•çš„ mean çš„å½¢çŠ¶
                    # shape é€šå¸¸æ˜¯ (1, D)
                    param_shape = normalizer.params_dict[key]['mean'].shape
                    # æ„é€  (B, D) çš„å…¨0æ•°æ®
                    dummy = torch.zeros((batch_pc.shape[0], *param_shape[1:]), device=device)
                    obs_dict[key] = dummy

            # --- D. å½’ä¸€åŒ– ---
            # normalizer.normalize(dict) åªä¼šå¤„ç† dict ä¸­å­˜åœ¨çš„ key
            # å¹¶ä¸”ä¼šå¿½ç•¥ 'action' (å› ä¸º action é€šå¸¸åœ¨ normalizer['action'] é‡Œå•ç‹¬å¤„ç†)
            nobs = normalizer.normalize(obs_dict)
            
            # å¤„ç†é¢œè‰²
            if hasattr(policy, 'use_pc_color') and policy.use_pc_color:
                nobs['point_cloud'][..., 3:] /= 1.0
            else:
                nobs['point_cloud'] = nobs['point_cloud'][..., :]

            # --- E. Encoder æ¨ç† ---
            encoded = encoder(nobs)
            
            if len(encoded.shape) > 2:
                encoded = encoded.reshape(encoded.shape[0], -1)
            embeddings_list.append(encoded)


    # åˆå¹¶æ‰€æœ‰ batch
    X = torch.cat(embeddings_list, dim=0)
    print(f"âœ… Features extracted. Shape: {X.shape}")

    # 6. K-Means èšç±»
    K = 10 # èšç±»æ•°é‡
    print(f"ğŸ§© Running K-Means (k={K})...")
    centers, labels, density = kmeans_pytorch(X, k=K, n_iter=1000)

    # 7. ä¿å­˜ç»“æœ
    output_file = "clustering_results_1130_DMP_augmented.pt"
    save_dict = {
        "centers": centers.cpu(),
        "labels": labels.cpu(),
        "density": density.cpu()
    }
    torch.save(save_dict, output_file)
    
    print("-" * 30)
    print(f"ğŸ’¾ Results saved to {output_file}")
    print(f"   Top 10 Cluster Counts: {torch.topk(density, 10).values}")
    print("-" * 30)
    
    # é¢å¤–ï¼šè¿™é‡Œå¯ä»¥ç»™å‡ºä¸€ä¸ªæç¤ºï¼Œå¦‚ä½•åœ¨ BalancerWorkspace ä¸­åŠ è½½å®ƒ
    print("To use in BalancerWorkspace:")
    print("self.encoder_map = torch.load('clustering_results.pt')['centers']")
    print("self.weights_map = ... (calculate based on density)")

if __name__ == "__main__":
    main()